{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Semantic Chunking\n",
    "- SemanticChunker is a document splitter that uses embedding similarity between sentences to decide chunk boundaries.\n",
    "\n",
    "- It ensures that each chunk is semantically coherent and not cut off mid-thought like traditional character/token splitters."
   ],
   "id": "1baeae672ba2d5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T07:44:57.226346Z",
     "start_time": "2025-11-06T07:44:49.694356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ],
   "id": "c309c321669269c0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/binod.kafle/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T07:50:44.668320Z",
     "start_time": "2025-11-06T07:50:37.889652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Initialize the model\n",
    "model=SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "## Sample text\n",
    "text=\"\"\"\n",
    "LangChain is a framework for building applications with LLMs.\n",
    "Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\n",
    "You can create chains, agents, memory, and retrievers.\n",
    "The Eiffel Tower is located in Paris.\n",
    "France is a popular tourist destination.\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: Split into sentences\n",
    "sentences=[s.strip() for s in text.split(\"\\n\") if s.strip()]\n",
    "\n",
    "# step 2: Embed each sentence\n",
    "embeddings=model.encode(sentences)\n",
    "\n",
    "# Step 3: Initialize parameters\n",
    "threshold = 0.7  # control chunk tightness\n",
    "chunks = []\n",
    "current_chunk=[sentences[0]]\n",
    "\n",
    "## Step 4: Semantic grouping based on a threshold\n",
    "for i in range(1, len(sentences)):\n",
    "    sim = cosine_similarity(\n",
    "        [embeddings[i - 1]],\n",
    "        [embeddings[i]]\n",
    "    )[0][0]\n",
    "\n",
    "    if sim>=threshold:\n",
    "        current_chunk.append(sentences[i])\n",
    "    else:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "        current_chunk=[sentences[i]]\n",
    "\n",
    "# Append the last chunk\n",
    "chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "# Output the chunks\n",
    "print(\"\\nðŸ“Œ Semantic Chunks:\")\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print(f\"\\nChunk {idx+1}:\\n{chunk}\")"
   ],
   "id": "beb464febf2b3e79",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ Semantic Chunks:\n",
      "\n",
      "Chunk 1:\n",
      "LangChain is a framework for building applications with LLMs. Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\n",
      "\n",
      "Chunk 2:\n",
      "You can create chains, agents, memory, and retrievers.\n",
      "\n",
      "Chunk 3:\n",
      "The Eiffel Tower is located in Paris.\n",
      "\n",
      "Chunk 4:\n",
      "France is a popular tourist destination.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### RAG Pipeline Modular Coding",
   "id": "e70f0bca838d1c16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T08:02:55.668127Z",
     "start_time": "2025-11-06T08:02:55.619784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_classic.schema.runnable import RunnableLambda, RunnableMap\n",
    "from langchain_classic.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n"
   ],
   "id": "16d231fdcfd2a317",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T08:00:46.371145Z",
     "start_time": "2025-11-06T08:00:46.366785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Custom semantic chunker with Threshold\n",
    "\n",
    "class ThresholdSemanticChunker:\n",
    "    def __init__(self, model_name=\"all-MiniLM-L6-v2\", threshold=0.7):\n",
    "        self.model=SentenceTransformer(model_name)\n",
    "        self.threshold=threshold\n",
    "\n",
    "    def split(self, text: str):\n",
    "        sentences = [s.strip() for s in text.split('.') if s.strip()]\n",
    "        embeddings = self.model.encode(sentences)\n",
    "        chunks = []\n",
    "        current_chunk = [sentences[0]]\n",
    "\n",
    "        for i in range(1, len(sentences)):\n",
    "            sim = cosine_similarity([embeddings[i - 1]], [embeddings[i]])[0][0]\n",
    "            if sim >= self.threshold:\n",
    "                current_chunk.append(sentences[i])\n",
    "            else:\n",
    "                chunks.append(\". \".join(current_chunk) + \".\")\n",
    "                current_chunk = [sentences[i]]\n",
    "\n",
    "        chunks.append(\". \".join(current_chunk) + \".\")\n",
    "        return chunks\n",
    "\n",
    "    def split_documents(self,docs):\n",
    "        result=[]\n",
    "        for doc in docs:\n",
    "            for chunk in self.split(doc.page_content):\n",
    "                result.append(Document(page_content=chunk, metadata=doc.metadata))\n",
    "\n",
    "        return result"
   ],
   "id": "211d56f226e154f1",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T07:59:39.593361Z",
     "start_time": "2025-11-06T07:59:39.583260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sample text\n",
    "sample_text = \"\"\"\n",
    "LangChain is a framework for building applications with LLMs.\n",
    "Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\n",
    "You can create chains, agents, memory, and retrievers.\n",
    "The Eiffel Tower is located in Paris.\n",
    "France is a popular tourist destination.\n",
    "\"\"\"\n",
    "\n",
    "doc = Document(page_content=sample_text)\n",
    "doc"
   ],
   "id": "65b1e38cf2850813",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='\\nLangChain is a framework for building applications with LLMs.\\nLangchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\\nYou can create chains, agents, memory, and retrievers.\\nThe Eiffel Tower is located in Paris.\\nFrance is a popular tourist destination.\\n')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T08:00:59.281548Z",
     "start_time": "2025-11-06T08:00:51.853418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chunking\n",
    "chunker=ThresholdSemanticChunker(threshold=0.7)\n",
    "chunks=chunker.split_documents([doc])\n",
    "chunks"
   ],
   "id": "9205decee056c9c7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='LangChain is a framework for building applications with LLMs. Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.'),\n",
       " Document(metadata={}, page_content='You can create chains, agents, memory, and retrievers.'),\n",
       " Document(metadata={}, page_content='The Eiffel Tower is located in Paris.'),\n",
       " Document(metadata={}, page_content='France is a popular tourist destination.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T08:03:07.523975Z",
     "start_time": "2025-11-06T08:02:59.609620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### VectorStore\n",
    "embedding=HuggingFaceEmbeddings()\n",
    "vectorstore=FAISS.from_documents(chunks,embedding)\n",
    "retriever=vectorstore.as_retriever()"
   ],
   "id": "e52c548b6a4dc048",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T08:03:41.529452Z",
     "start_time": "2025-11-06T08:03:41.520478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Prompt Template\n",
    "\n",
    "# --- 5. Prompt Template ---\n",
    "template = \"\"\"Answer the question based on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt"
   ],
   "id": "e060b25c408503ce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based on the following context:\\n\\n{context}\\n\\nQuestion: {question}\\n')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T08:06:46.707978Z",
     "start_time": "2025-11-06T08:06:45.319454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## LLM\n",
    "llm=init_chat_model(model=\"groq:openai/gpt-oss-20b\",temperature=0.4)\n",
    "\n",
    "### LCEL Chain With retrieval\n",
    "\n",
    "rag_chain=(\n",
    "    RunnableMap(\n",
    "        {\n",
    "        \"context\": lambda x: retriever.invoke(x[\"question\"]),\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        }\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# --- 8. Run Query ---\n",
    "query = {\"question\": \"What is LangChain used for?\"}\n",
    "result = rag_chain.invoke(query)\n",
    "\n",
    "print(result)"
   ],
   "id": "68f8416130950786",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a framework for building applications that use large language models (LLMs). It offers modular abstractions that let developers combine LLMs with other tools (e.g., OpenAI, Pinecone) to create chains, agents, memory, and retrievers.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Semantic chunker With Langchain",
   "id": "5576529faf962720"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:10:29.830042Z",
     "start_time": "2025-11-06T11:10:28.747975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_experimental.text_splitters import SemanticChunker"
   ],
   "id": "5a4df6ba6f97cd7",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:17:17.983828Z",
     "start_time": "2025-11-06T11:17:10.475476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the documents\n",
    "loader = TextLoader(\"langchain_intro.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Initialize embedding model\n",
    "embedding = HuggingFaceEmbeddings(model=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# create semantic chunker\n",
    "chunker = SemanticChunker(embedding)\n",
    "\n",
    "## Result\n",
    "for i,chunk in enumerate(chunks):\n",
    "    print(f\"\\n chunk {i+1}:\\n{chunk.page_content}\")\n"
   ],
   "id": "da3de0d12079d41a",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SemanticChunker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[20]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      6\u001B[39m embedding = HuggingFaceEmbeddings(model=\u001B[33m\"\u001B[39m\u001B[33mall-MiniLM-L6-v2\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# create semantic chunker\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m chunker = \u001B[43mSemanticChunker\u001B[49m(embedding)\n\u001B[32m     11\u001B[39m \u001B[38;5;66;03m## Result\u001B[39;00m\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i,chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(chunks):\n",
      "\u001B[31mNameError\u001B[39m: name 'SemanticChunker' is not defined"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7a4276fc106d3547"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
