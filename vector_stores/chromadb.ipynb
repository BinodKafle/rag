{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Building a RAG System with LangChain and ChromaDB\n",
    "#### Introduction\n",
    "Retrieval-Augmented Generation (RAG) is a powerful technique that combines the capabilities of large language models with external knowledge retrieval. This notebook will walk you through building a complete RAG system using:\n",
    "\n",
    "- LangChain: A framework for developing applications powered by language models\n",
    "- ChromaDB: An open-source vector database for storing and retrieving embeddings\n",
    "- OpenAI: For embeddings and language model (you can substitute with other providers)"
   ],
   "id": "87b5f5de643efa49"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:12:31.917845Z",
     "start_time": "2025-11-04T08:12:31.898243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "id": "b447bb8629a9055c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:35:58.235995Z",
     "start_time": "2025-11-04T08:35:58.230113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# langchain imports\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "# vector stores\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# utility imports\n",
    "import numpy as np\n",
    "from typing import List"
   ],
   "id": "26a33dcd4c576eca",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:17:12.123628Z",
     "start_time": "2025-11-04T08:17:12.105112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# RAG Architecture Overview\n",
    "print(\"\"\"\n",
    "RAG (Retrieval-Augmented Generation) Architecture:\n",
    "\n",
    "1. Document Loading: Load documents from various sources\n",
    "2. Document Splitting: Break documents into smaller chunks\n",
    "3. Embedding Generation: Convert chunks into vector representations\n",
    "4. Vector Storage: Store embeddings in ChromaDB\n",
    "5. Query Processing: Convert user query to embedding\n",
    "6. Similarity Search: Find relevant chunks from vector store\n",
    "7. Context Augmentation: Combine retrieved chunks with query\n",
    "8. Response Generation: LLM generates answer using context\n",
    "\n",
    "Benefits of RAG:\n",
    "- Reduces hallucinations\n",
    "- Provides up-to-date information\n",
    "- Allows citing sources\n",
    "- Works with domain-specific knowledge\n",
    "\"\"\")"
   ],
   "id": "2ccad1d810558455",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAG (Retrieval-Augmented Generation) Architecture:\n",
      "\n",
      "1. Document Loading: Load documents from various sources\n",
      "2. Document Splitting: Break documents into smaller chunks\n",
      "3. Embedding Generation: Convert chunks into vector representations\n",
      "4. Vector Storage: Store embeddings in ChromaDB\n",
      "5. Query Processing: Convert user query to embedding\n",
      "6. Similarity Search: Find relevant chunks from vector store\n",
      "7. Context Augmentation: Combine retrieved chunks with query\n",
      "8. Response Generation: LLM generates answer using context\n",
      "\n",
      "Benefits of RAG:\n",
      "- Reduces hallucinations\n",
      "- Provides up-to-date information\n",
      "- Allows citing sources\n",
      "- Works with domain-specific knowledge\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Sample Data\n",
   "id": "b04f552b5102b16e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:17:59.048438Z",
     "start_time": "2025-11-04T08:17:59.037899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## create sample documents\n",
    "sample_docs = [\n",
    "    \"\"\"\n",
    "    Machine Learning Fundamentals\n",
    "\n",
    "    Machine learning is a subset of artificial intelligence that enables systems to learn\n",
    "    and improve from experience without being explicitly programmed. There are three main\n",
    "    types of machine learning: supervised learning, unsupervised learning, and reinforcement\n",
    "    learning. Supervised learning uses labeled data to train models, while unsupervised\n",
    "    learning finds patterns in unlabeled data. Reinforcement learning learns through\n",
    "    interaction with an environment using rewards and penalties.\n",
    "    \"\"\",\n",
    "\n",
    "    \"\"\"\n",
    "    Deep Learning and Neural Networks\n",
    "\n",
    "    Deep learning is a subset of machine learning based on artificial neural networks.\n",
    "    These networks are inspired by the human brain and consist of layers of interconnected\n",
    "    nodes. Deep learning has revolutionized fields like computer vision, natural language\n",
    "    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly\n",
    "    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers\n",
    "    excel at sequential data processing.\n",
    "    \"\"\",\n",
    "\n",
    "    \"\"\"\n",
    "    Natural Language Processing (NLP)\n",
    "\n",
    "    NLP is a field of AI that focuses on the interaction between computers and human language.\n",
    "    Key tasks in NLP include text classification, named entity recognition, sentiment analysis,\n",
    "    machine translation, and question answering. Modern NLP heavily relies on transformer\n",
    "    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand\n",
    "    context and relationships between words in text.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "sample_docs"
   ],
   "id": "b4f7251bff120953",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n    Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through \\n    interaction with an environment using rewards and penalties.\\n    ',\n",
       " '\\n    Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \\n    excel at sequential data processing.\\n    ',\n",
       " '\\n    Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.\\n    ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:19:42.895149Z",
     "start_time": "2025-11-04T08:19:42.886068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## save sample documents to files\n",
    "import tempfile\n",
    "temp_dir=tempfile.mkdtemp()\n",
    "\n",
    "for i,doc in enumerate(sample_docs):\n",
    "    with open(f\"{temp_dir}/doc_{i}.txt\",\"w\") as f:\n",
    "        f.write(doc)\n",
    "\n",
    "print(f\"Sample document create in : {temp_dir}\")"
   ],
   "id": "92f7f34238c040cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample document create in : /var/folders/_m/nv9cbmbs6h38d0yjvxbgmhpj_vx45m/T/tmpdwbk0gzl\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:20:52.854007Z",
     "start_time": "2025-11-04T08:20:52.847400Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/var/folders/_m/nv9cbmbs6h38d0yjvxbgmhpj_vx45m/T/tmp7l41hk8j'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8,
   "source": "temp_dir",
   "id": "ed2c3fb7dd5b1724"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:23:16.279785Z",
     "start_time": "2025-11-04T08:23:16.272548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## save sample documents to files\n",
    "import tempfile\n",
    "temp_dir=tempfile.mkdtemp()\n",
    "\n",
    "for i,doc in enumerate(sample_docs):\n",
    "    with open(f\"doc_{i}.txt\",\"w\") as f:\n",
    "        f.write(doc)"
   ],
   "id": "714daa303ed9075d",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Document Loading",
   "id": "4e1f9d2708dc18cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:23:37.599202Z",
     "start_time": "2025-11-04T08:23:37.582862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader,TextLoader\n",
    "\n",
    "# Load documents from directory\n",
    "loader = DirectoryLoader(\n",
    "    \"data\",\n",
    "    glob=\"*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={'encoding': 'utf-8'}\n",
    ")\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "print(f\"\\nFirst document preview:\")\n",
    "print(documents[0].page_content[:200] + \"...\")"
   ],
   "id": "d15ff341b657ee6c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n",
      "\n",
      "First document preview:\n",
      "\n",
      "    Natural Language Processing (NLP)\n",
      "\n",
      "    NLP is a field of AI that focuses on the interaction between computers and human language. \n",
      "    Key tasks in NLP include text classification, named entity r...\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Document Splitting",
   "id": "95c5362886d64da8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:25:40.244724Z",
     "start_time": "2025-11-04T08:25:40.226279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,  # Maximum size of each chunk\n",
    "    chunk_overlap=50,  # Overlap between chunks to maintain context\n",
    "    length_function=len,\n",
    "    separators=[\" \"]  # Hierarchy of separators\n",
    ")\n",
    "chunks=text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks from {len(documents)} documents\")\n",
    "print(f\"\\nChunk example:\")\n",
    "print(f\"Content: {chunks[0].page_content[:150]}...\")\n",
    "print(f\"Metadata: {chunks[0].metadata}\")"
   ],
   "id": "1270fd855e642903",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 5 chunks from 3 documents\n",
      "\n",
      "Chunk example:\n",
      "Content: Natural Language Processing (NLP)\n",
      "\n",
      "    NLP is a field of AI that focuses on the interaction between computers and human language. \n",
      "    Key tasks in NL...\n",
      "Metadata: {'source': 'data/doc_2.txt'}\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Embedding Models",
   "id": "ec762ded4a22296c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:29:11.790511Z",
     "start_time": "2025-11-04T08:29:05.687764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "sample_text=\"Machine learning is fascinating\"\n",
    "embeddings=HuggingFaceEmbeddings(\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "embeddings"
   ],
   "id": "36cfb3e033c71700",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, query_encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:29:34.781876Z",
     "start_time": "2025-11-04T08:29:34.198945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vector = embeddings.embed_query(sample_text)\n",
    "vector"
   ],
   "id": "a95fe7069396d3ce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.047630079090595245,\n",
       " -0.09523382037878036,\n",
       " 0.08622034639120102,\n",
       " 0.00824981089681387,\n",
       " 0.012193546630442142,\n",
       " -0.0504952147603035,\n",
       " -0.007320779841393232,\n",
       " -0.05885450914502144,\n",
       " -0.03901909664273262,\n",
       " -0.028660980984568596,\n",
       " -0.08570096641778946,\n",
       " 0.07921118289232254,\n",
       " 0.004685688763856888,\n",
       " -0.021504931151866913,\n",
       " -0.07088707387447357,\n",
       " 0.014649459160864353,\n",
       " -0.013478770852088928,\n",
       " -0.01538170501589775,\n",
       " -0.0821557343006134,\n",
       " -0.12226202338933945,\n",
       " -0.003417207859456539,\n",
       " 0.013044722378253937,\n",
       " -0.008553915657103062,\n",
       " 0.007963724434375763,\n",
       " 0.02498508244752884,\n",
       " 0.018824271857738495,\n",
       " 0.06268894672393799,\n",
       " 0.019554147496819496,\n",
       " 0.046845246106386185,\n",
       " -0.0665501058101654,\n",
       " 0.0034160115756094456,\n",
       " 0.06802238523960114,\n",
       " -0.011118337512016296,\n",
       " 0.030044367536902428,\n",
       " -0.09648732095956802,\n",
       " 0.027357475832104683,\n",
       " 0.009005132131278515,\n",
       " 0.01710323803126812,\n",
       " 0.04554044082760811,\n",
       " 0.006371451076120138,\n",
       " -0.005477506201714277,\n",
       " -0.04323989897966385,\n",
       " 0.03637201711535454,\n",
       " -0.004953158088028431,\n",
       " 0.11256805062294006,\n",
       " 0.10895714163780212,\n",
       " -0.05888416990637779,\n",
       " -0.08978400379419327,\n",
       " 0.0141758369281888,\n",
       " -0.004923616535961628,\n",
       " -0.12424919754266739,\n",
       " -0.041505977511405945,\n",
       " -0.030205078423023224,\n",
       " -0.009998981840908527,\n",
       " -0.08218611031770706,\n",
       " 0.018560068681836128,\n",
       " 0.05275704339146614,\n",
       " -0.021651867777109146,\n",
       " -0.003514969488605857,\n",
       " -0.018109619617462158,\n",
       " 0.018467608839273453,\n",
       " -0.07166920602321625,\n",
       " -0.0766030102968216,\n",
       " -5.187618444324471e-05,\n",
       " 0.08697866648435593,\n",
       " -0.022721273824572563,\n",
       " -0.001688616699539125,\n",
       " 0.03807215392589569,\n",
       " -0.018713615834712982,\n",
       " -0.03861036151647568,\n",
       " -0.048196613788604736,\n",
       " 0.12013337761163712,\n",
       " 0.01635143905878067,\n",
       " 0.11162298172712326,\n",
       " 0.07147171348333359,\n",
       " 0.03678680211305618,\n",
       " 0.0485801137983799,\n",
       " 0.04590979963541031,\n",
       " 0.09048043191432953,\n",
       " 0.044882822781801224,\n",
       " 0.019618185237050056,\n",
       " -0.0677834153175354,\n",
       " 0.008881249465048313,\n",
       " 0.04076339676976204,\n",
       " 0.06069209426641464,\n",
       " -0.1289784014225006,\n",
       " -0.04271577298641205,\n",
       " -0.0032787304371595383,\n",
       " -0.009827847592532635,\n",
       " 0.0005153402453288436,\n",
       " -0.003069823607802391,\n",
       " 0.005194326397031546,\n",
       " 0.031786542385816574,\n",
       " -0.09975671023130417,\n",
       " -0.014281690120697021,\n",
       " 0.03796965256333351,\n",
       " 0.0005381900118663907,\n",
       " -0.054501619189977646,\n",
       " 0.013058527372777462,\n",
       " 0.09638987481594086,\n",
       " -0.08256550133228302,\n",
       " 0.023379629477858543,\n",
       " 0.03767923265695572,\n",
       " 0.018936149775981903,\n",
       " 0.04331536218523979,\n",
       " -0.011235179379582405,\n",
       " 0.054047971963882446,\n",
       " 0.013554341159760952,\n",
       " 0.15480855107307434,\n",
       " -0.11832719296216965,\n",
       " -0.021119166165590286,\n",
       " 0.06041419506072998,\n",
       " 0.03231498971581459,\n",
       " -0.06339868158102036,\n",
       " 0.01684173382818699,\n",
       " -0.008745048195123672,\n",
       " 0.028255129233002663,\n",
       " 0.023477701470255852,\n",
       " -0.005007089581340551,\n",
       " 0.06584011763334274,\n",
       " -0.03957681730389595,\n",
       " 0.004732223227620125,\n",
       " -0.08012418448925018,\n",
       " 0.0401187464594841,\n",
       " 0.02900293655693531,\n",
       " -0.07128507643938065,\n",
       " -0.0523969866335392,\n",
       " -1.851413520778688e-33,\n",
       " -0.022458771243691444,\n",
       " -0.05324171110987663,\n",
       " 0.03741137683391571,\n",
       " 0.03622002527117729,\n",
       " 0.058388855308294296,\n",
       " -0.10132134705781937,\n",
       " -0.04294366389513016,\n",
       " -0.07153544574975967,\n",
       " -0.002205644967034459,\n",
       " 0.009916245937347412,\n",
       " -0.034962523728609085,\n",
       " 0.09678727388381958,\n",
       " 0.014809869229793549,\n",
       " 0.0154794380068779,\n",
       " 0.013518020510673523,\n",
       " -0.023244677111506462,\n",
       " -0.05069880187511444,\n",
       " 0.06064729392528534,\n",
       " -0.0100433100014925,\n",
       " -0.06408008933067322,\n",
       " 0.02763614058494568,\n",
       " 0.016566423699259758,\n",
       " 0.05769829452037811,\n",
       " 0.021269841119647026,\n",
       " -0.041610341519117355,\n",
       " 0.034677762538194656,\n",
       " 0.026389585807919502,\n",
       " -0.024245811626315117,\n",
       " 0.06398738920688629,\n",
       " 0.037308670580387115,\n",
       " -0.027789244428277016,\n",
       " 0.004934545140713453,\n",
       " -0.0850943773984909,\n",
       " 0.01161597017198801,\n",
       " 0.005482240114361048,\n",
       " 0.010303878225386143,\n",
       " -0.0059953476302325726,\n",
       " -0.024837182834744453,\n",
       " 0.08113262802362442,\n",
       " 0.027461819350719452,\n",
       " 0.024977419525384903,\n",
       " -0.05153563246130943,\n",
       " 0.026391224935650826,\n",
       " -0.07550922781229019,\n",
       " -0.03513885289430618,\n",
       " 0.026748977601528168,\n",
       " 0.05017085000872612,\n",
       " -0.07794104516506195,\n",
       " -0.01852073147892952,\n",
       " -0.0736594945192337,\n",
       " -0.06532638520002365,\n",
       " -0.02050768956542015,\n",
       " -0.03154165670275688,\n",
       " -0.012163512408733368,\n",
       " 0.04202697426080704,\n",
       " 0.058418143540620804,\n",
       " 0.03136269748210907,\n",
       " 0.012510503642261028,\n",
       " -0.005927555728703737,\n",
       " -0.0035784118808805943,\n",
       " 0.009319163858890533,\n",
       " 0.06265721470117569,\n",
       " 0.014164161868393421,\n",
       " 0.044353023171424866,\n",
       " -0.03204594552516937,\n",
       " 0.05018293485045433,\n",
       " 0.04910435527563095,\n",
       " -0.004869114141911268,\n",
       " 0.056327998638153076,\n",
       " 0.04199821874499321,\n",
       " -0.0063480231910943985,\n",
       " 0.03242769464850426,\n",
       " 0.03214241564273834,\n",
       " -0.09874062240123749,\n",
       " -0.02146388217806816,\n",
       " -0.025022678077220917,\n",
       " 0.04340207949280739,\n",
       " -0.03051716275513172,\n",
       " -0.026508240029215813,\n",
       " 0.005576755851507187,\n",
       " -0.05787796527147293,\n",
       " -0.034901753067970276,\n",
       " 0.03966335207223892,\n",
       " -0.047214325517416,\n",
       " 0.015531040728092194,\n",
       " 0.0009009838104248047,\n",
       " 0.013943322002887726,\n",
       " -0.0856940895318985,\n",
       " -0.07319217920303345,\n",
       " 0.03837176784873009,\n",
       " -0.05251690372824669,\n",
       " -0.0404340885579586,\n",
       " 0.0675303116440773,\n",
       " -0.00397181510925293,\n",
       " -0.07288111746311188,\n",
       " 1.5378933817090446e-33,\n",
       " -0.13390973210334778,\n",
       " -0.01202597189694643,\n",
       " 0.018825681880116463,\n",
       " 0.10021144151687622,\n",
       " -0.01992262713611126,\n",
       " 0.006540010217577219,\n",
       " -0.07442919164896011,\n",
       " 0.026667602360248566,\n",
       " -0.06070569530129433,\n",
       " 0.03277287632226944,\n",
       " 0.057513147592544556,\n",
       " 0.03343760594725609,\n",
       " 0.08132783323526382,\n",
       " 0.015304472297430038,\n",
       " 0.013942863792181015,\n",
       " 0.03363724425435066,\n",
       " -0.023404890671372414,\n",
       " 0.015400437638163567,\n",
       " -0.04267463833093643,\n",
       " 0.00570281594991684,\n",
       " 0.007098222151398659,\n",
       " 0.10701969265937805,\n",
       " -0.04363337904214859,\n",
       " -0.013974180445075035,\n",
       " 0.028677547350525856,\n",
       " 0.008382124826312065,\n",
       " -0.08829443156719208,\n",
       " -0.001931122737005353,\n",
       " 0.023776933550834656,\n",
       " 0.031566981226205826,\n",
       " -0.07297559827566147,\n",
       " 0.004157837014645338,\n",
       " -0.05567466840147972,\n",
       " -0.033967141062021255,\n",
       " -0.06280222535133362,\n",
       " 0.0537114255130291,\n",
       " 0.023145411163568497,\n",
       " -0.022650670260190964,\n",
       " 0.01337825134396553,\n",
       " 0.10647505521774292,\n",
       " 0.029187370091676712,\n",
       " 0.009746605530381203,\n",
       " -0.031947072595357895,\n",
       " -0.027531441301107407,\n",
       " -0.01369123812764883,\n",
       " -0.05204363167285919,\n",
       " 0.004957884084433317,\n",
       " 0.022883381694555283,\n",
       " 0.03773298114538193,\n",
       " -0.020572228357195854,\n",
       " 0.026852862909436226,\n",
       " 0.048874542117118835,\n",
       " -0.047059424221515656,\n",
       " -0.07500675320625305,\n",
       " -0.0464450865983963,\n",
       " 0.020885176956653595,\n",
       " -0.039417773485183716,\n",
       " 0.002546886447817087,\n",
       " 0.07679827511310577,\n",
       " 0.05375228822231293,\n",
       " -0.11899693310260773,\n",
       " -0.008447672240436077,\n",
       " 0.009597831405699253,\n",
       " 0.04310065880417824,\n",
       " 0.008501380681991577,\n",
       " -0.006365740206092596,\n",
       " -0.026686586439609528,\n",
       " 0.04639569669961929,\n",
       " -0.08796434849500656,\n",
       " -0.08304376155138016,\n",
       " 0.03635285049676895,\n",
       " 0.031748216599226,\n",
       " -0.05327318608760834,\n",
       " 0.06381670385599136,\n",
       " -0.04489894583821297,\n",
       " -0.025313660502433777,\n",
       " 0.011110103689134121,\n",
       " -0.046704743057489395,\n",
       " -0.07605023682117462,\n",
       " -0.018422242254018784,\n",
       " 0.0671527087688446,\n",
       " -0.08439598977565765,\n",
       " 0.035344772040843964,\n",
       " 0.04648496210575104,\n",
       " 0.031017666682600975,\n",
       " 0.10328133404254913,\n",
       " 0.05221908539533615,\n",
       " -0.036084771156311035,\n",
       " -0.011852255091071129,\n",
       " -0.017376966774463654,\n",
       " -0.044900860637426376,\n",
       " 0.032585736364126205,\n",
       " -0.027540694922208786,\n",
       " 0.06971312314271927,\n",
       " -0.014728449285030365,\n",
       " -1.1417438550154202e-08,\n",
       " 0.011337357573211193,\n",
       " 0.0066169872879981995,\n",
       " 0.052554577589035034,\n",
       " -0.06144791096448898,\n",
       " 0.0935952365398407,\n",
       " 0.022909892722964287,\n",
       " -0.02789224497973919,\n",
       " 0.11478246748447418,\n",
       " -0.1028931736946106,\n",
       " 0.014907561242580414,\n",
       " 0.0883999839425087,\n",
       " -0.020931774750351906,\n",
       " -0.0012170635163784027,\n",
       " 0.10379938036203384,\n",
       " 0.0536823496222496,\n",
       " 0.018039768561720848,\n",
       " 0.038349542766809464,\n",
       " 0.04144173488020897,\n",
       " -0.023413239046931267,\n",
       " 0.044205501675605774,\n",
       " 0.06359721720218658,\n",
       " 0.04357867315411568,\n",
       " 0.05021532252430916,\n",
       " -0.021383708342909813,\n",
       " 0.029354004189372063,\n",
       " -0.024863392114639282,\n",
       " -0.03058624267578125,\n",
       " 0.01965370960533619,\n",
       " 0.06094491109251976,\n",
       " 0.00047281195293180645,\n",
       " -0.07703293859958649,\n",
       " 0.09105832874774933,\n",
       " 0.01881440356373787,\n",
       " 0.015357558615505695,\n",
       " 0.07740551233291626,\n",
       " 0.06075727194547653,\n",
       " -0.008226661942899227,\n",
       " -0.06321875751018524,\n",
       " -0.04141618311405182,\n",
       " -0.04288209229707718,\n",
       " -0.021910181269049644,\n",
       " 0.06281844526529312,\n",
       " -0.060461051762104034,\n",
       " 0.03939471021294594,\n",
       " -0.01059755776077509,\n",
       " 0.0284104160964489,\n",
       " 0.04063556343317032,\n",
       " -0.09052859246730804,\n",
       " 0.018001463264226913,\n",
       " 0.0732802227139473,\n",
       " 0.05442804470658302,\n",
       " -0.008709526620805264,\n",
       " 0.07332158833742142,\n",
       " 0.06096161901950836,\n",
       " 0.09512171894311905,\n",
       " -0.003931814339011908,\n",
       " -0.006277372129261494,\n",
       " -0.03624698892235756,\n",
       " -0.04820757359266281,\n",
       " 0.11870301514863968,\n",
       " 0.07818420976400375,\n",
       " 0.07516178488731384,\n",
       " -0.021452030166983604,\n",
       " -0.05170658230781555]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Intilialize the ChromaDB Vector Store And Stores the chunks in Vector Representation",
   "id": "92305526af9d0932"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:36:56.000275Z",
     "start_time": "2025-11-04T08:36:49.089746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a chromadb vector store\n",
    "\n",
    "persist_directory=\"./chroma_db\"\n",
    "\n",
    "## Initialize chroma with hugging face embeddings\n",
    "vectorstore=Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=HuggingFaceEmbeddings(),\n",
    "    persist_directory=persist_directory,\n",
    "    collection_name=\"rag_collection\"\n",
    ")\n",
    "\n",
    "print(f\"Vector store created with {vectorstore._collection.count()} vectors\")\n",
    "print(f\"Persisted to: {persist_directory}\")"
   ],
   "id": "80bb56fe8dd85e69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created with 10 vectors\n",
      "Persisted to: ./chroma_db\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test Similarity Search",
   "id": "756799ab41418d40"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:40:21.440546Z",
     "start_time": "2025-11-04T08:40:21.053626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query=\"What are the types of machine learning?\"\n",
    "\n",
    "similar_docs=vectorstore.similarity_search(query,k=3)\n",
    "similar_docs"
   ],
   "id": "a29e06b31876524e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'data/doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'data/doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:40:50.336205Z",
     "start_time": "2025-11-04T08:40:49.375942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query=\"what is NLP?\"\n",
    "\n",
    "similar_docs=vectorstore.similarity_search(query,k=3)\n",
    "similar_docs"
   ],
   "id": "c1c1c40fcf1c2dbc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.'),\n",
       " Document(metadata={'source': 'data/doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.'),\n",
       " Document(metadata={'source': 'data/doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:41:11.305171Z",
     "start_time": "2025-11-04T08:41:10.568239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query=\"what is Deep Learning?\"\n",
    "\n",
    "similar_docs=vectorstore.similarity_search(query,k=3)\n",
    "similar_docs"
   ],
   "id": "4626e9e52b6e8bc0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       " Document(metadata={'source': 'data/doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       " Document(metadata={'source': 'data/doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:42:35.392051Z",
     "start_time": "2025-11-04T08:42:35.379680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Query: {query}\")\n",
    "print(f\"\\nTop {len(similar_docs)} similar chunks:\")\n",
    "for i, doc in enumerate(similar_docs):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(doc.page_content[:200] + \"...\")\n",
    "    print(f\"Source: {doc.metadata.get('source', 'Unknown')}\")"
   ],
   "id": "563132fcdc630545",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: what is Deep Learning?\n",
      "\n",
      "Top 3 similar chunks:\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of i...\n",
      "Source: data/doc_1.txt\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of i...\n",
      "Source: data/doc_1.txt\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are...\n",
      "Source: data/doc_0.txt\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Advanced Similarity Search With Scores",
   "id": "23ff84921a514375"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:45:35.970922Z",
     "start_time": "2025-11-04T08:45:35.572690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_scores = vectorstore.similarity_search_with_score(query, k=3)\n",
    "results_scores"
   ],
   "id": "1641acc1f21efd28",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'data/doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       "  0.4973111152648926),\n",
       " (Document(metadata={'source': 'data/doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       "  0.4973111152648926),\n",
       " (Document(metadata={'source': 'data/doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  0.8716008067131042)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Understanding Similarity Scores\n",
    "The similarity score represents how closely related a document chunk is to your query. The scoring depends on the distance metric used:\n",
    "\n",
    "ChromaDB default: Uses L2 distance (Euclidean distance)\n",
    "\n",
    "- Lower scores = MORE similar (closer in vector space)\n",
    "- Score of 0 = identical vectors\n",
    "- Typical range: 0 to 2 (but can be higher)\n",
    "\n",
    "\n",
    "Cosine similarity (if configured):\n",
    "\n",
    "- Higher scores = MORE similar\n",
    "- Range: -1 to 1 (1 being identical)"
   ],
   "id": "9c44f50806a4dd39"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Initialize LLM, RAG Chain, Prompt Template, Query the RAG system",
   "id": "1d139933a99212cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:49:21.474869Z",
     "start_time": "2025-11-04T08:49:21.083264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")"
   ],
   "id": "526f15c3053262bc",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:50:25.033416Z",
     "start_time": "2025-11-04T08:50:22.142662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_response = llm.invoke(\"What is Large Language Models\")\n",
    "test_response"
   ],
   "id": "3bd3c32e10bcad91",
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRateLimitError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[36]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m test_response = \u001B[43mllm\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mWhat is Large Language Models\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      2\u001B[39m test_response\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:379\u001B[39m, in \u001B[36mBaseChatModel.invoke\u001B[39m\u001B[34m(self, input, config, stop, **kwargs)\u001B[39m\n\u001B[32m    365\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m    366\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvoke\u001B[39m(\n\u001B[32m    367\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    372\u001B[39m     **kwargs: Any,\n\u001B[32m    373\u001B[39m ) -> AIMessage:\n\u001B[32m    374\u001B[39m     config = ensure_config(config)\n\u001B[32m    375\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(\n\u001B[32m    376\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mAIMessage\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    377\u001B[39m         cast(\n\u001B[32m    378\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mChatGeneration\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m--> \u001B[39m\u001B[32m379\u001B[39m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    380\u001B[39m \u001B[43m                \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_convert_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    381\u001B[39m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    382\u001B[39m \u001B[43m                \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcallbacks\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    383\u001B[39m \u001B[43m                \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtags\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    384\u001B[39m \u001B[43m                \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    385\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_name\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    386\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_id\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    387\u001B[39m \u001B[43m                \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    388\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m.generations[\u001B[32m0\u001B[39m][\u001B[32m0\u001B[39m],\n\u001B[32m    389\u001B[39m         ).message,\n\u001B[32m    390\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1088\u001B[39m, in \u001B[36mBaseChatModel.generate_prompt\u001B[39m\u001B[34m(self, prompts, stop, callbacks, **kwargs)\u001B[39m\n\u001B[32m   1079\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m   1080\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mgenerate_prompt\u001B[39m(\n\u001B[32m   1081\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1085\u001B[39m     **kwargs: Any,\n\u001B[32m   1086\u001B[39m ) -> LLMResult:\n\u001B[32m   1087\u001B[39m     prompt_messages = [p.to_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[32m-> \u001B[39m\u001B[32m1088\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:903\u001B[39m, in \u001B[36mBaseChatModel.generate\u001B[39m\u001B[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[39m\n\u001B[32m    900\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(input_messages):\n\u001B[32m    901\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    902\u001B[39m         results.append(\n\u001B[32m--> \u001B[39m\u001B[32m903\u001B[39m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    904\u001B[39m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    905\u001B[39m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    906\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    907\u001B[39m \u001B[43m                \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    908\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    909\u001B[39m         )\n\u001B[32m    910\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    911\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1192\u001B[39m, in \u001B[36mBaseChatModel._generate_with_cache\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1190\u001B[39m     result = generate_from_stream(\u001B[38;5;28miter\u001B[39m(chunks))\n\u001B[32m   1191\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m inspect.signature(\u001B[38;5;28mself\u001B[39m._generate).parameters.get(\u001B[33m\"\u001B[39m\u001B[33mrun_manager\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m-> \u001B[39m\u001B[32m1192\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1193\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m   1194\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1195\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1196\u001B[39m     result = \u001B[38;5;28mself\u001B[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1299\u001B[39m, in \u001B[36mBaseChatOpenAI._generate\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1297\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m raw_response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(raw_response, \u001B[33m\"\u001B[39m\u001B[33mhttp_response\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m   1298\u001B[39m         e.response = raw_response.http_response  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1299\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[32m   1300\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   1301\u001B[39m     \u001B[38;5;28mself\u001B[39m.include_response_headers\n\u001B[32m   1302\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m raw_response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1303\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(raw_response, \u001B[33m\"\u001B[39m\u001B[33mheaders\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   1304\u001B[39m ):\n\u001B[32m   1305\u001B[39m     generation_info = {\u001B[33m\"\u001B[39m\u001B[33mheaders\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mdict\u001B[39m(raw_response.headers)}\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1294\u001B[39m, in \u001B[36mBaseChatOpenAI._generate\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1287\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m _construct_lc_result_from_responses_api(\n\u001B[32m   1288\u001B[39m             response,\n\u001B[32m   1289\u001B[39m             schema=original_schema_obj,\n\u001B[32m   1290\u001B[39m             metadata=generation_info,\n\u001B[32m   1291\u001B[39m             output_version=\u001B[38;5;28mself\u001B[39m.output_version,\n\u001B[32m   1292\u001B[39m         )\n\u001B[32m   1293\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1294\u001B[39m         raw_response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwith_raw_response\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mpayload\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1295\u001B[39m         response = raw_response.parse()\n\u001B[32m   1296\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/openai/_legacy_response.py:364\u001B[39m, in \u001B[36mto_raw_response_wrapper.<locals>.wrapped\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    360\u001B[39m extra_headers[RAW_RESPONSE_HEADER] = \u001B[33m\"\u001B[39m\u001B[33mtrue\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    362\u001B[39m kwargs[\u001B[33m\"\u001B[39m\u001B[33mextra_headers\u001B[39m\u001B[33m\"\u001B[39m] = extra_headers\n\u001B[32m--> \u001B[39m\u001B[32m364\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m cast(LegacyAPIResponse[R], \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py:286\u001B[39m, in \u001B[36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    284\u001B[39m             msg = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[32m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    285\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[32m--> \u001B[39m\u001B[32m286\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:1156\u001B[39m, in \u001B[36mCompletions.create\u001B[39m\u001B[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001B[39m\n\u001B[32m   1110\u001B[39m \u001B[38;5;129m@required_args\u001B[39m([\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m], [\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m   1111\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcreate\u001B[39m(\n\u001B[32m   1112\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1153\u001B[39m     timeout: \u001B[38;5;28mfloat\u001B[39m | httpx.Timeout | \u001B[38;5;28;01mNone\u001B[39;00m | NotGiven = not_given,\n\u001B[32m   1154\u001B[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001B[32m   1155\u001B[39m     validate_response_format(response_format)\n\u001B[32m-> \u001B[39m\u001B[32m1156\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1157\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m/chat/completions\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1158\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1159\u001B[39m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m   1160\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmessages\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1161\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmodel\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1162\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43maudio\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43maudio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1163\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfrequency_penalty\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1164\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfunction_call\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1165\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfunctions\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1166\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlogit_bias\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1167\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlogprobs\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1168\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmax_completion_tokens\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_completion_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1169\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmax_tokens\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1170\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1171\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmodalities\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodalities\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1172\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mn\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1173\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mparallel_tool_calls\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel_tool_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1174\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mprediction\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1175\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mpresence_penalty\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1176\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mprompt_cache_key\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt_cache_key\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1177\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mreasoning_effort\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mreasoning_effort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1178\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mresponse_format\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1179\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43msafety_identifier\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43msafety_identifier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1180\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mseed\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1181\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mservice_tier\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mservice_tier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1182\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstop\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1183\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstore\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1184\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstream\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1185\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstream_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1186\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtemperature\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1187\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtool_choice\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1188\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtools\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1189\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtop_logprobs\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1190\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtop_p\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1191\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43muser\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1192\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mverbosity\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbosity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1193\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mweb_search_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mweb_search_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1194\u001B[39m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1195\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mCompletionCreateParamsStreaming\u001B[49m\n\u001B[32m   1196\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\n\u001B[32m   1197\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mCompletionCreateParamsNonStreaming\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1198\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1199\u001B[39m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1200\u001B[39m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\n\u001B[32m   1201\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1202\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m=\u001B[49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1203\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1204\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1205\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/openai/_base_client.py:1259\u001B[39m, in \u001B[36mSyncAPIClient.post\u001B[39m\u001B[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[39m\n\u001B[32m   1245\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpost\u001B[39m(\n\u001B[32m   1246\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1247\u001B[39m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1254\u001B[39m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1255\u001B[39m ) -> ResponseT | _StreamT:\n\u001B[32m   1256\u001B[39m     opts = FinalRequestOptions.construct(\n\u001B[32m   1257\u001B[39m         method=\u001B[33m\"\u001B[39m\u001B[33mpost\u001B[39m\u001B[33m\"\u001B[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001B[32m   1258\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1259\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/openai/_base_client.py:1047\u001B[39m, in \u001B[36mSyncAPIClient.request\u001B[39m\u001B[34m(self, cast_to, options, stream, stream_cls)\u001B[39m\n\u001B[32m   1044\u001B[39m             err.response.read()\n\u001B[32m   1046\u001B[39m         log.debug(\u001B[33m\"\u001B[39m\u001B[33mRe-raising status error\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1047\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._make_status_error_from_response(err.response) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1049\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m   1051\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mcould not resolve response (should never happen)\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mRateLimitError\u001B[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:51:59.910792Z",
     "start_time": "2025-11-04T08:51:59.880901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.chat_models.base import init_chat_model\n",
    "\n",
    "llm=init_chat_model(\"openai:gpt-3.5-turbo\")\n",
    "#llm=init_chat_model(\"groq:\")\n",
    "llm"
   ],
   "id": "50c11160a096bb15",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x357ae0690>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x357ae0410>, root_client=<openai.OpenAI object at 0x357ae0a50>, root_async_client=<openai.AsyncOpenAI object at 0x357ae0b90>, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:52:14.459154Z",
     "start_time": "2025-11-04T08:52:10.245773Z"
    }
   },
   "cell_type": "code",
   "source": "llm.invoke(\"What is AI\")",
   "id": "c396f4d65980a538",
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRateLimitError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[38]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mllm\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mWhat is AI\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:379\u001B[39m, in \u001B[36mBaseChatModel.invoke\u001B[39m\u001B[34m(self, input, config, stop, **kwargs)\u001B[39m\n\u001B[32m    365\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m    366\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvoke\u001B[39m(\n\u001B[32m    367\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    372\u001B[39m     **kwargs: Any,\n\u001B[32m    373\u001B[39m ) -> AIMessage:\n\u001B[32m    374\u001B[39m     config = ensure_config(config)\n\u001B[32m    375\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(\n\u001B[32m    376\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mAIMessage\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    377\u001B[39m         cast(\n\u001B[32m    378\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mChatGeneration\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m--> \u001B[39m\u001B[32m379\u001B[39m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    380\u001B[39m \u001B[43m                \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_convert_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    381\u001B[39m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    382\u001B[39m \u001B[43m                \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcallbacks\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    383\u001B[39m \u001B[43m                \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtags\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    384\u001B[39m \u001B[43m                \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    385\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_name\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    386\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_id\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    387\u001B[39m \u001B[43m                \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    388\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m.generations[\u001B[32m0\u001B[39m][\u001B[32m0\u001B[39m],\n\u001B[32m    389\u001B[39m         ).message,\n\u001B[32m    390\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1088\u001B[39m, in \u001B[36mBaseChatModel.generate_prompt\u001B[39m\u001B[34m(self, prompts, stop, callbacks, **kwargs)\u001B[39m\n\u001B[32m   1079\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m   1080\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mgenerate_prompt\u001B[39m(\n\u001B[32m   1081\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1085\u001B[39m     **kwargs: Any,\n\u001B[32m   1086\u001B[39m ) -> LLMResult:\n\u001B[32m   1087\u001B[39m     prompt_messages = [p.to_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[32m-> \u001B[39m\u001B[32m1088\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:903\u001B[39m, in \u001B[36mBaseChatModel.generate\u001B[39m\u001B[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[39m\n\u001B[32m    900\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(input_messages):\n\u001B[32m    901\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    902\u001B[39m         results.append(\n\u001B[32m--> \u001B[39m\u001B[32m903\u001B[39m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    904\u001B[39m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    905\u001B[39m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    906\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    907\u001B[39m \u001B[43m                \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    908\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    909\u001B[39m         )\n\u001B[32m    910\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    911\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1192\u001B[39m, in \u001B[36mBaseChatModel._generate_with_cache\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1190\u001B[39m     result = generate_from_stream(\u001B[38;5;28miter\u001B[39m(chunks))\n\u001B[32m   1191\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m inspect.signature(\u001B[38;5;28mself\u001B[39m._generate).parameters.get(\u001B[33m\"\u001B[39m\u001B[33mrun_manager\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m-> \u001B[39m\u001B[32m1192\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1193\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m   1194\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1195\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1196\u001B[39m     result = \u001B[38;5;28mself\u001B[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1299\u001B[39m, in \u001B[36mBaseChatOpenAI._generate\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1297\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m raw_response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(raw_response, \u001B[33m\"\u001B[39m\u001B[33mhttp_response\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m   1298\u001B[39m         e.response = raw_response.http_response  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1299\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[32m   1300\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   1301\u001B[39m     \u001B[38;5;28mself\u001B[39m.include_response_headers\n\u001B[32m   1302\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m raw_response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1303\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(raw_response, \u001B[33m\"\u001B[39m\u001B[33mheaders\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   1304\u001B[39m ):\n\u001B[32m   1305\u001B[39m     generation_info = {\u001B[33m\"\u001B[39m\u001B[33mheaders\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mdict\u001B[39m(raw_response.headers)}\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1294\u001B[39m, in \u001B[36mBaseChatOpenAI._generate\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1287\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m _construct_lc_result_from_responses_api(\n\u001B[32m   1288\u001B[39m             response,\n\u001B[32m   1289\u001B[39m             schema=original_schema_obj,\n\u001B[32m   1290\u001B[39m             metadata=generation_info,\n\u001B[32m   1291\u001B[39m             output_version=\u001B[38;5;28mself\u001B[39m.output_version,\n\u001B[32m   1292\u001B[39m         )\n\u001B[32m   1293\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1294\u001B[39m         raw_response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwith_raw_response\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mpayload\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1295\u001B[39m         response = raw_response.parse()\n\u001B[32m   1296\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/openai/_legacy_response.py:364\u001B[39m, in \u001B[36mto_raw_response_wrapper.<locals>.wrapped\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    360\u001B[39m extra_headers[RAW_RESPONSE_HEADER] = \u001B[33m\"\u001B[39m\u001B[33mtrue\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    362\u001B[39m kwargs[\u001B[33m\"\u001B[39m\u001B[33mextra_headers\u001B[39m\u001B[33m\"\u001B[39m] = extra_headers\n\u001B[32m--> \u001B[39m\u001B[32m364\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m cast(LegacyAPIResponse[R], \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py:286\u001B[39m, in \u001B[36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    284\u001B[39m             msg = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[32m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    285\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[32m--> \u001B[39m\u001B[32m286\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:1156\u001B[39m, in \u001B[36mCompletions.create\u001B[39m\u001B[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001B[39m\n\u001B[32m   1110\u001B[39m \u001B[38;5;129m@required_args\u001B[39m([\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m], [\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m   1111\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcreate\u001B[39m(\n\u001B[32m   1112\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1153\u001B[39m     timeout: \u001B[38;5;28mfloat\u001B[39m | httpx.Timeout | \u001B[38;5;28;01mNone\u001B[39;00m | NotGiven = not_given,\n\u001B[32m   1154\u001B[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001B[32m   1155\u001B[39m     validate_response_format(response_format)\n\u001B[32m-> \u001B[39m\u001B[32m1156\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1157\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m/chat/completions\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1158\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1159\u001B[39m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m   1160\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmessages\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1161\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmodel\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1162\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43maudio\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43maudio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1163\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfrequency_penalty\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1164\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfunction_call\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1165\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfunctions\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1166\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlogit_bias\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1167\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlogprobs\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1168\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmax_completion_tokens\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_completion_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1169\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmax_tokens\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1170\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1171\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmodalities\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodalities\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1172\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mn\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1173\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mparallel_tool_calls\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel_tool_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1174\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mprediction\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1175\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mpresence_penalty\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1176\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mprompt_cache_key\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt_cache_key\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1177\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mreasoning_effort\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mreasoning_effort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1178\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mresponse_format\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1179\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43msafety_identifier\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43msafety_identifier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1180\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mseed\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1181\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mservice_tier\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mservice_tier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1182\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstop\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1183\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstore\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1184\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstream\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1185\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstream_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1186\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtemperature\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1187\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtool_choice\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1188\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtools\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1189\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtop_logprobs\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1190\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtop_p\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1191\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43muser\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1192\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mverbosity\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbosity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1193\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mweb_search_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mweb_search_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1194\u001B[39m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1195\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mCompletionCreateParamsStreaming\u001B[49m\n\u001B[32m   1196\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\n\u001B[32m   1197\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mCompletionCreateParamsNonStreaming\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1198\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1199\u001B[39m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1200\u001B[39m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\n\u001B[32m   1201\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1202\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m=\u001B[49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1203\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1204\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1205\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/openai/_base_client.py:1259\u001B[39m, in \u001B[36mSyncAPIClient.post\u001B[39m\u001B[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[39m\n\u001B[32m   1245\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpost\u001B[39m(\n\u001B[32m   1246\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1247\u001B[39m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1254\u001B[39m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1255\u001B[39m ) -> ResponseT | _StreamT:\n\u001B[32m   1256\u001B[39m     opts = FinalRequestOptions.construct(\n\u001B[32m   1257\u001B[39m         method=\u001B[33m\"\u001B[39m\u001B[33mpost\u001B[39m\u001B[33m\"\u001B[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001B[32m   1258\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1259\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/openai/_base_client.py:1047\u001B[39m, in \u001B[36mSyncAPIClient.request\u001B[39m\u001B[34m(self, cast_to, options, stream, stream_cls)\u001B[39m\n\u001B[32m   1044\u001B[39m             err.response.read()\n\u001B[32m   1046\u001B[39m         log.debug(\u001B[33m\"\u001B[39m\u001B[33mRe-raising status error\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1047\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._make_status_error_from_response(err.response) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1049\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m   1051\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mcould not resolve response (should never happen)\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mRateLimitError\u001B[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Modern RAG Chain",
   "id": "5412b787aa35b0d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:02:07.316475Z",
     "start_time": "2025-11-04T09:02:07.226522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain"
   ],
   "id": "496a6b3f8bf23087",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.chains'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[41]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mchains\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m create_retrieval_chain\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain_core\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mprompts\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ChatPromptTemplate\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mchains\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcombine_documents\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m create_stuff_documents_chain\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'langchain.chains'"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:02:47.472079Z",
     "start_time": "2025-11-04T09:02:47.420536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Convert vector store to retriever\n",
    "retriever=vectorstore.as_retriever(\n",
    "    search_kwarg={\"k\":3} ## Retrieve top 3 relevant chunks\n",
    ")\n",
    "retriever"
   ],
   "id": "2d129e862c12b6db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x140740e10>, search_kwargs={})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T03:56:56.400947Z",
     "start_time": "2025-11-06T03:56:51.457865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Create a prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "system_prompt=\"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ],
   "id": "263aa5a60a05f09c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/binod.kafle/Documents/personal/learning/rag/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T03:57:01.335048Z",
     "start_time": "2025-11-06T03:57:01.330261Z"
    }
   },
   "cell_type": "code",
   "source": "prompt",
   "id": "3eab1de6dd68076c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the question.\\nIf you don't know the answer, just say that you don't know.\\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:01:08.039045Z",
     "start_time": "2025-11-06T04:00:59.081962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Create a document chain\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "document_chain=create_stuff_documents_chain(llm,prompt)\n",
    "document_chain"
   ],
   "id": "e62fd27f8afea854",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m### Create a document chain\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain_classic\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mchains\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcombine_documents\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m create_stuff_documents_chain\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m document_chain=create_stuff_documents_chain(\u001B[43mllm\u001B[49m,prompt)\n\u001B[32m      4\u001B[39m document_chain\n",
      "\u001B[31mNameError\u001B[39m: name 'llm' is not defined"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This chain:\n",
    "\n",
    "- Takes retrieved documents\n",
    "- \"Stuffs\" them into the prompt's {context} placeholder\n",
    "- Sends the complete prompt to the LLM\n",
    "- Returns the LLM's response"
   ],
   "id": "17ddffaa0361bff4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### What is create_retrieval_chain?\n",
    "create_retrieval_chain is a function that combines a retriever (which fetches relevant documents) with a document chain (which processes those documents with an LLM) to create a complete RAG pipeline."
   ],
   "id": "2f93bd150409fd7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:04:38.559964Z",
     "start_time": "2025-11-06T04:04:38.488804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Create The Final RAG Chain\n",
    "from langchain_classic.chains import create_retrieval_chain\n",
    "rag_chain=create_retrieval_chain(retriever,document_chain)\n",
    "rag_chain"
   ],
   "id": "5019c65322149e59",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m### Create The Final RAG Chain\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain_classic\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mchains\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m create_retrieval_chain\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m rag_chain=create_retrieval_chain(\u001B[43mretriever\u001B[49m,document_chain)\n\u001B[32m      4\u001B[39m rag_chain\n",
      "\u001B[31mNameError\u001B[39m: name 'retriever' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:04:58.857146Z",
     "start_time": "2025-11-06T04:04:58.835256Z"
    }
   },
   "cell_type": "code",
   "source": "response=rag_chain.invoke({\"input\":\"What is Deep LEarning\"})",
   "id": "6dd43d93bab4fea8",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rag_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m response=\u001B[43mrag_chain\u001B[49m.invoke({\u001B[33m\"\u001B[39m\u001B[33minput\u001B[39m\u001B[33m\"\u001B[39m:\u001B[33m\"\u001B[39m\u001B[33mWhat is Deep LEarning\u001B[39m\u001B[33m\"\u001B[39m})\n",
      "\u001B[31mNameError\u001B[39m: name 'rag_chain' is not defined"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:05:06.836673Z",
     "start_time": "2025-11-06T04:05:06.815008Z"
    }
   },
   "cell_type": "code",
   "source": "response",
   "id": "6cb409549eab29ed",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mresponse\u001B[49m\n",
      "\u001B[31mNameError\u001B[39m: name 'response' is not defined"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:05:14.483030Z",
     "start_time": "2025-11-06T04:05:14.451100Z"
    }
   },
   "cell_type": "code",
   "source": "response['answer']",
   "id": "2b337115dfbe0589",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mresponse\u001B[49m[\u001B[33m'\u001B[39m\u001B[33manswer\u001B[39m\u001B[33m'\u001B[39m]\n",
      "\u001B[31mNameError\u001B[39m: name 'response' is not defined"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T04:08:48.550638Z",
     "start_time": "2025-11-06T04:08:48.503806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to query the modern RAG system\n",
    "def query_rag_modern(question):\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Using create_retrieval_chain approach\n",
    "    result = rag_chain.invoke({\"input\": question})\n",
    "\n",
    "    print(f\"Answer: {result['answer']}\")\n",
    "    print(\"\\nRetrieved Context:\")\n",
    "    for i, doc in enumerate(result['context']):\n",
    "        print(f\"\\n--- Source {i+1} ---\")\n",
    "        print(doc.page_content[:200] + \"...\")\n",
    "\n",
    "    return result\n",
    "\n",
    "# Test queries\n",
    "test_questions = [\n",
    "    \"What are the three types of machine learning?\",\n",
    "    \"What is deep learning and how does it relate to neural networks?\",\n",
    "    \"What are CNNs best used for?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    result = query_rag_modern(question)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ],
   "id": "b8846be7a1204ebb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the three types of machine learning?\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rag_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 25\u001B[39m\n\u001B[32m     18\u001B[39m test_questions = [\n\u001B[32m     19\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mWhat are the three types of machine learning?\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     20\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mWhat is deep learning and how does it relate to neural networks?\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     21\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mWhat are CNNs best used for?\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     22\u001B[39m ]\n\u001B[32m     24\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m question \u001B[38;5;129;01min\u001B[39;00m test_questions:\n\u001B[32m---> \u001B[39m\u001B[32m25\u001B[39m     result = \u001B[43mquery_rag_modern\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquestion\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     26\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m + \u001B[33m\"\u001B[39m\u001B[33m=\u001B[39m\u001B[33m\"\u001B[39m*\u001B[32m80\u001B[39m + \u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 7\u001B[39m, in \u001B[36mquery_rag_modern\u001B[39m\u001B[34m(question)\u001B[39m\n\u001B[32m      4\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m-\u001B[39m\u001B[33m\"\u001B[39m * \u001B[32m50\u001B[39m)\n\u001B[32m      6\u001B[39m \u001B[38;5;66;03m# Using create_retrieval_chain approach\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m result = \u001B[43mrag_chain\u001B[49m.invoke({\u001B[33m\"\u001B[39m\u001B[33minput\u001B[39m\u001B[33m\"\u001B[39m: question})\n\u001B[32m      9\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mAnswer: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult[\u001B[33m'\u001B[39m\u001B[33manswer\u001B[39m\u001B[33m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     10\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mRetrieved Context:\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mNameError\u001B[39m: name 'rag_chain' is not defined"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f53573f2117e6928"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
